import diffusers.models
from .config import args, reflen

if args.diffuser_model == 'UNet2DConditionModel':
    # TODO: set down_block_types, block_out_channels and more parameters of UNet2DConditionModel
    diffuser_model = diffusers.models.UNet2DConditionModel(
        sample_size=reflen + 1,
        in_channels=1,
        out_channels=1
        # center_input_sample = False,
        # flip_sin_to_cos = True,
        # freq_shift: int = 0,
        # down_block_types: = (
        #     "CrossAttnDownBlock2D",
        #     "CrossAttnDownBlock2D",
        #     "CrossAttnDownBlock2D",
        #     "DownBlock2D",
        # ),
        # mid_block_type: Optional[str] = "UNetMidBlock2DCrossAttn",
        # up_block_types: Tuple[str] = ("UpBlock2D", "CrossAttnUpBlock2D", "CrossAttnUpBlock2D", "CrossAttnUpBlock2D"),
        # only_cross_attention: Union[bool, Tuple[bool]] = False,
        # block_out_channels: Tuple[int] = (320, 640, 1280, 1280),
        # layers_per_block: Union[int, Tuple[int]] = 2,
        # downsample_padding: int = 1,
        # mid_block_scale_factor: float = 1,
        # dropout: float = 0.0,
        # act_fn: str = "silu",
        # norm_num_groups: Optional[int] = 32,
        # norm_eps: float = 1e-5,
        # cross_attention_dim: Union[int, Tuple[int]] = 1280,
        # transformer_layers_per_block: Union[int, Tuple[int], Tuple[Tuple]] = 1,
        # reverse_transformer_layers_per_block: Optional[Tuple[Tuple[int]]] = None,
        # encoder_hid_dim: Optional[int] = None,
        # encoder_hid_dim_type: Optional[str] = None,
        # attention_head_dim: Union[int, Tuple[int]] = 8,
        # num_attention_heads: Optional[Union[int, Tuple[int]]] = None,
        # dual_cross_attention: bool = False,
        # use_linear_projection: bool = False,
        # class_embed_type: Optional[str] = None,
        # addition_embed_type: Optional[str] = None,
        # addition_time_embed_dim: Optional[int] = None,
        # num_class_embeds: Optional[int] = None,
        # upcast_attention: bool = False,
        # resnet_time_scale_shift: str = "default",
        # resnet_skip_time_act: bool = False,
        # resnet_out_scale_factor: float = 1.0,
        # time_embedding_type: str = "positional",
        # time_embedding_dim: Optional[int] = None,
        # time_embedding_act_fn: Optional[str] = None,
        # timestep_post_act: Optional[str] = None,
        # time_cond_proj_dim: Optional[int] = None,
        # conv_in_kernel: int = 3,
        # conv_out_kernel: int = 3,
        # projection_class_embeddings_input_dim: Optional[int] = None,
        # attention_type: str = "default",
        # class_embeddings_concat: bool = False,
        # mid_block_only_cross_attention: Optional[bool] = None,
        # cross_attention_norm: Optional[str] = None,
        # addition_embed_type_num_heads: int = 64,
    )
